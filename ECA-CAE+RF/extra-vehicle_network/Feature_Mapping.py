import os
import numpy as np
import pandas as pd
from PIL import Image
from collections import Counter
from sklearn.preprocessing import MinMaxScaler
from tqdm import tqdm
import pickle

# ========== é…ç½®å‚æ•° ==========
WINDOW_SIZE = 3  # 3æ¡æ•°æ®
STRIDE = 3  # ä¸é‡å 
FEATURE_DIM = 80  # æ¯æ¡æ•°æ®80ä¸ªç‰¹å¾

IMG_H, IMG_W, CHANNELS = 9, 9, 3  # 9Ã—9Ã—3 = 243 (240ç‰¹å¾ + 3 padding)

# å®šä¹‰æ ‡ç­¾æ˜ å°„
LABEL_MAP = {
    "BENIGN": 0,
    "DoS": 1,
    "PortScan": 2,
    "BruteForce": 3,
    "WebAttack": 4,
    "Bot": 5,
    "Infiltration": 6
}
INV_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}

# å°‘æ•°ç±»ï¼ˆå…¨éƒ¨ä¿ç•™ï¼‰
MINORITY_CLASSES = ["WebAttack", "Bot", "Infiltration"]

# å¤šæ•°ç±»çª—å£æ•°é‡é™åˆ¶
MAJORITY_CLASS_LIMITS = {
    "BENIGN": 18423,
    "DoS": 7234,
    "PortScan": 5436,
    "BruteForce": None  # ä¸é™åˆ¶
}

OUTPUT_ROOT = "CICIDS2017_images"


def load_and_preprocess_csv(csv_path):
    """åŠ è½½CSVå¹¶é¢„å¤„ç†"""
    print("ğŸ“‚ Loading CSV file...")
    df = pd.read_csv(csv_path)

    # åˆ é™¤ç©ºå€¼
    original_len = len(df)
    df = df.dropna()
    print(f"âœ“ Removed {original_len - len(df)} rows with missing values")

    # æŒ‰Timestampæ’åºï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if 'Timestamp' in df.columns:
        df = df.sort_values("Timestamp").reset_index(drop=True)

    # æå–ç‰¹å¾åˆ—ï¼ˆé™¤äº†Timestampå’ŒLabelï¼‰
    exclude_cols = ['Timestamp', 'Label', ' Timestamp', ' Label']
    feature_cols = [col for col in df.columns if col not in exclude_cols]

    print(f"âœ“ Found {len(feature_cols)} feature columns")

    # å¤„ç†éæ•°å€¼åˆ—
    features_df = df[feature_cols]
    for col in feature_cols:
        if features_df[col].dtype == 'object':
            features_df[col] = pd.to_numeric(features_df[col], errors='coerce')

    features = features_df.values.astype(np.float32)
    labels = df["Label"].values if "Label" in df.columns else df[" Label"].values

    # æ›¿æ¢infå’Œnan
    features = np.nan_to_num(features, nan=0.0, posinf=1e10, neginf=-1e10)

    return features, labels, feature_cols


def normalize_features(features):
    """å½’ä¸€åŒ–ç‰¹å¾åˆ°[0,1]"""
    scaler = MinMaxScaler()
    features_norm = scaler.fit_transform(features)
    return features_norm, scaler


def window_to_rgb_image(window):
    """
    å°†3Ã—80çš„çª—å£æ˜ å°„åˆ°9Ã—9Ã—3çš„RGBå›¾åƒ
    å‚è€ƒåŸå§‹ä»£ç çš„æ˜ å°„é€»è¾‘ï¼š
    - æ—¶é—´æ­¥tçš„é€šé“: c = t // 9
    - æ—¶é—´æ­¥tçš„è¡Œ: i = t % 9
    - ç‰¹å¾fçš„åˆ—: j = f

    è°ƒæ•´åï¼š3æ¡æ•°æ®ï¼Œ80ä¸ªç‰¹å¾
    - å°†80ä¸ªç‰¹å¾åˆ†3ç»„æ˜ å°„åˆ°3ä¸ªé€šé“
    - æ¯ä¸ªé€šé“éœ€è¦27ä¸ªä½ç½® (9Ã—3)
    - 3Ã—27 = 81 > 80ï¼Œæ‰€ä»¥æ¯ä¸ªé€šé“æ”¾27ä¸ªï¼Œå…¶ä¸­ç¬¬3ä¸ªé€šé“æœ€åä¸€ä¸ªpadding
    """
    img = np.zeros((IMG_H, IMG_W, CHANNELS), dtype=np.float32)

    # å±•å¹³çª—å£: 3Ã—80 = 240
    flat_features = window.flatten()

    # è¡¥3ä¸ªpaddingåˆ°243
    padded_features = np.pad(flat_features, (0, 3), mode='constant', constant_values=0)

    # æŒ‰ç…§åŸå§‹é€»è¾‘æ˜ å°„ï¼šæŒ‰æ—¶é—´æ­¥éå†ï¼Œæ¯ä¸ªæ—¶é—´æ­¥å†…éå†ç‰¹å¾
    idx = 0
    for t in range(WINDOW_SIZE):  # 3ä¸ªæ—¶é—´æ­¥
        for f in range(FEATURE_DIM):  # 80ä¸ªç‰¹å¾
            c = idx // (IMG_H * IMG_W)  # é€šé“
            temp = idx % (IMG_H * IMG_W)
            i = temp // IMG_W  # è¡Œ
            j = temp % IMG_W  # åˆ—
            img[i, j, c] = padded_features[idx]
            idx += 1

    # å¡«å……æœ€å3ä¸ªpadding
    for _ in range(3):
        c = idx // (IMG_H * IMG_W)
        temp = idx % (IMG_H * IMG_W)
        i = temp // IMG_W
        j = temp % IMG_W
        img[i, j, c] = 0.0
        idx += 1

    return img


def image_to_features(img, scaler=None):
    """
    ä»9Ã—9Ã—3çš„RGBå›¾åƒåæ¨åŸå§‹ç‰¹å¾
    è¿”å›3Ã—80çš„çª—å£ï¼ˆå»é™¤paddingï¼‰
    å¦‚æœæä¾›scalerï¼Œåˆ™åå½’ä¸€åŒ–
    """
    # æŒ‰ç…§ç›¸åŒçš„æ˜ å°„é€»è¾‘æå–
    flat_features = []

    for idx in range(240):  # åªå–å‰240ä¸ªï¼ˆå»é™¤paddingï¼‰
        c = idx // (IMG_H * IMG_W)
        temp = idx % (IMG_H * IMG_W)
        i = temp // IMG_W
        j = temp % IMG_W
        flat_features.append(img[i, j, c])

    features_flat = np.array(flat_features)

    # é‡å¡‘ä¸º3Ã—80
    window = features_flat.reshape(WINDOW_SIZE, FEATURE_DIM)

    # åå½’ä¸€åŒ–
    if scaler is not None:
        window = scaler.inverse_transform(window)

    return window


def majority_label(window_labels):
    """è¿”å›çª—å£ä¸­å‡ºç°æœ€å¤šçš„æ ‡ç­¾ID"""
    most_common = Counter(window_labels).most_common(1)[0][0]
    return LABEL_MAP.get(most_common, -1)


def save_image(img, path):
    """ä¿å­˜å›¾åƒ"""
    img_uint8 = (img * 255).clip(0, 255).astype(np.uint8)
    Image.fromarray(img_uint8).save(path)


def generate_windows_for_class(features, labels, class_name, max_windows=None):
    """ä¸ºå•ä¸ªç±»åˆ«ç”Ÿæˆçª—å£"""
    windows = []
    idx = 0

    while idx + WINDOW_SIZE <= len(features):
        if max_windows and len(windows) >= max_windows:
            break

        window_feat = features[idx:idx + WINDOW_SIZE]
        window_labels = labels[idx:idx + WINDOW_SIZE]

        # ç¡®ä¿çª—å£å†…æ ‡ç­¾ä¸€è‡´æ€§ï¼ˆmajority votingï¼‰
        label_id = majority_label(window_labels)

        windows.append({
            "features": window_feat,
            "label": label_id
        })

        idx += STRIDE

    return windows


def process_class(features, labels, class_name, img_id_start, max_windows=None):
    """å¤„ç†å•ä¸ªç±»åˆ«å¹¶ç”Ÿæˆå›¾åƒ"""
    print(f"\n{'=' * 50}")
    print(f"ğŸ¯ Processing class: {class_name}")
    print(f"   Total samples: {len(features)}")
    if max_windows:
        print(f"   Window limit: {max_windows}")

    label_id = LABEL_MAP[class_name]
    output_dir = os.path.join(OUTPUT_ROOT, str(label_id))
    os.makedirs(output_dir, exist_ok=True)

    # ç”Ÿæˆçª—å£
    windows = generate_windows_for_class(features, labels, class_name, max_windows)
    print(f"   Generated windows: {len(windows)}")

    # ä¿å­˜å›¾åƒ
    img_id = img_id_start
    for w in tqdm(windows, desc=f"Saving {class_name} images"):
        img = window_to_rgb_image(w["features"])

        save_path = os.path.join(
            output_dir,
            f"{class_name}_{img_id}.png"
        )

        save_image(img, save_path)
        img_id += 1

    return len(windows), img_id


def generate_full_image_dataset(csv_path):
    """ç”Ÿæˆå®Œæ•´çš„å›¾åƒæ•°æ®é›†"""
    # åŠ è½½æ•°æ®
    features, labels, feature_cols = load_and_preprocess_csv(csv_path)

    # å½’ä¸€åŒ–
    print("\nğŸ”„ Normalizing features...")
    features_norm, scaler = normalize_features(features)

    # ä¿å­˜scalerç”¨äºåç»­åå½’ä¸€åŒ–
    scaler_path = os.path.join(OUTPUT_ROOT, "scaler.pkl")
    os.makedirs(OUTPUT_ROOT, exist_ok=True)
    with open(scaler_path, 'wb') as f:
        pickle.dump(scaler, f)
    print(f"âœ“ Scaler saved to {scaler_path}")

    # ä¿å­˜ç‰¹å¾åˆ—åï¼ˆç”¨äºåç»­åˆ†æå’Œå¯è§£é‡Šæ€§ï¼‰
    feature_cols_path = os.path.join(OUTPUT_ROOT, "feature_columns.pkl")
    with open(feature_cols_path, 'wb') as f:
        pickle.dump(feature_cols, f)
    print(f"âœ“ Feature columns saved to {feature_cols_path}")

    # ç»Ÿè®¡å„ç±»åˆ«æ•°é‡
    print("\nğŸ“Š Original class distribution:")
    label_counts = Counter(labels)
    for label in sorted(LABEL_MAP.keys(), key=lambda x: LABEL_MAP[x]):
        count = label_counts.get(label, 0)
        print(f"   {label:15s}: {count:8d}")

    # åˆ†ç¦»å°‘æ•°ç±»å’Œå¤šæ•°ç±»
    print("\nğŸ” Separating classes...")
    class_data = {}
    for label_name in LABEL_MAP.keys():
        mask = labels == label_name
        class_data[label_name] = {
            "features": features_norm[mask],
            "labels": labels[mask]
        }
        print(f"   {label_name:15s}: {len(class_data[label_name]['features'])} samples")

    # åˆ›å»ºæ‰€æœ‰ç±»åˆ«æ–‡ä»¶å¤¹
    for cid in LABEL_MAP.values():
        os.makedirs(os.path.join(OUTPUT_ROOT, str(cid)), exist_ok=True)

    # å¤„ç†æ¯ä¸ªç±»åˆ«
    class_counter = Counter()
    img_id = 0

    print("\n" + "=" * 60)
    print("ğŸš€ Generating RGB images...")
    print("=" * 60)

    # å…ˆå¤„ç†å°‘æ•°ç±»ï¼ˆå…¨éƒ¨ä¿ç•™ï¼‰
    for class_name in MINORITY_CLASSES:
        if class_name in class_data:
            count, img_id = process_class(
                class_data[class_name]["features"],
                class_data[class_name]["labels"],
                class_name,
                img_id,
                max_windows=None  # ä¸é™åˆ¶
            )
            class_counter[LABEL_MAP[class_name]] = count

    # å†å¤„ç†å¤šæ•°ç±»ï¼ˆæœ‰é™åˆ¶ï¼‰
    for class_name, limit in MAJORITY_CLASS_LIMITS.items():
        if class_name in class_data:
            count, img_id = process_class(
                class_data[class_name]["features"],
                class_data[class_name]["labels"],
                class_name,
                img_id,
                max_windows=limit
            )
            class_counter[LABEL_MAP[class_name]] = count

    return scaler, class_counter, feature_cols


if __name__ == "__main__":
    # ä¿®æ”¹ä¸ºä½ çš„CSVè·¯å¾„
    csv_path = "./dataset/CICIDS2017_with_Timestamp.csv"

    print("=" * 60)
    print("CICIDS2017 Dataset to RGB Image Converter")
    print("=" * 60)

    scaler, class_counter, feature_cols = generate_full_image_dataset(csv_path)

    # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
    print("\n" + "=" * 60)
    print("ğŸ“Š Final Image Dataset Statistics:")
    print("=" * 60)
    total_images = 0
    for cid in sorted(class_counter.keys()):
        count = class_counter[cid]
        total_images += count
        print(f"Class {cid} ({INV_LABEL_MAP[cid]:15s}): {count:6d} images")

    print(f"\n{'Total':21s}: {total_images:6d} images")
    print(f"\nImages saved to: {OUTPUT_ROOT}/")
    print(f"Scaler saved to: {OUTPUT_ROOT}/scaler.pkl")
    print(f"Feature columns saved to: {OUTPUT_ROOT}/feature_columns.pkl")

    # æµ‹è¯•åå‘æ˜ å°„
    print("\n" + "=" * 60)
    print("ğŸ§ª Testing image-to-features conversion...")
    print("=" * 60)

    # è¯»å–ä¸€å¼ å›¾åƒè¿›è¡Œæµ‹è¯•
    test_class = 0  # BENIGN
    test_dir = os.path.join(OUTPUT_ROOT, str(test_class))
    if os.path.exists(test_dir):
        test_images = [f for f in os.listdir(test_dir) if f.endswith('.png')]
        if test_images:
            test_img_path = os.path.join(test_dir, test_images[0])
            test_img = np.array(Image.open(test_img_path)).astype(np.float32) / 255.0

            # åå‘æ˜ å°„
            recovered_features = image_to_features(test_img, scaler)

            print(f"âœ“ Test image: {test_images[0]}")
            print(f"âœ“ Recovered features shape: {recovered_features.shape}")
            print(f"âœ“ Feature range: [{recovered_features.min():.4f}, {recovered_features.max():.4f}]")
            print("\nâœ… Image-to-features conversion successful!")

            # æ˜¾ç¤ºéƒ¨åˆ†æ¢å¤çš„ç‰¹å¾ï¼ˆå‰3è¡Œï¼Œå‰5åˆ—ï¼‰
            print(f"\nğŸ“Š Sample recovered features (first 3 rows, first 5 columns):")
            print(recovered_features[:3, :5])