import os
import numpy as np
import pandas as pd
from PIL import Image
from collections import Counter
from sklearn.preprocessing import MinMaxScaler
from tqdm import tqdm
import pickle

# =================é…ç½®åŒºåŸŸ=================
WINDOW_SIZE = 27
STRIDE = 27  # ä¸é‡å æ»‘åŠ¨çª—å£
FEATURE_DIM = 9  # ID (1) + Data (8) = 9

IMG_H, IMG_W, CHANNELS = 9, 9, 3

# æ ¹æ®ä½ çš„æ•°æ®é›†åˆ†å¸ƒå®šä¹‰çš„æ ‡ç­¾æ˜ å°„
LABEL_MAP = {
    "BENIGN": 0,
    "DoS": 1,
    "RPM": 2,
    "SPEED": 3,
    "STEERING_WHEEL": 4,
    "GAS": 5
}
INV_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}

# ä½ æŒ‡å®šéœ€è¦è½¬æ¢çš„ç›®æ ‡ç±»åˆ«
TARGET_CLASSES = ["SPEED", "GAS", "STEERING_WHEEL"]

OUTPUT_ROOT = "./CICIoV2024_Images"
# =========================================

def load_data_no_timestamp(csv_path):
    """
    åŠ è½½æ•°æ®ï¼Œå‡è®¾CSVè¡Œé¡ºåºå³ä¸ºæ—¶é—´é¡ºåº
    """
    print(f"ğŸ“– Loading {csv_path} ...")
    df = pd.read_csv(csv_path)

    # âš ï¸å¦‚æœä¸ç¡®å®šåˆ—åï¼Œè¯·å–æ¶ˆä¸‹é¢è¿™è¡Œçš„æ³¨é‡Šæ¥æŸ¥çœ‹åˆ—å
    # print(df.columns)

    # å‡è®¾åˆ—ååŒ…å« ID, DATA0...DATA7, Label (æ ¹æ®CICé€šå¸¸çš„æ ¼å¼)
    # å¦‚æœä½ çš„åˆ—åæ˜¯å°å†™ (id, data0...) è¯·åœ¨è¿™é‡Œä¿®æ”¹
    feature_cols = ["ID"] + [f"DATA_{i}" for i in range(8)]

    # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨ï¼Œé˜²æ­¢æŠ¥é”™
    missing_cols = [c for c in feature_cols if c not in df.columns]
    if missing_cols:
        # å°è¯•æŸ¥æ‰¾ä¸åŒºåˆ†å¤§å°å†™çš„åŒ¹é…
        print(f"âš ï¸ Warning: Standard columns not found: {missing_cols}")
        print("Trying to auto-detect columns...")
        # ç®€å•çš„è‡ªåŠ¨ä¿®æ­£é€»è¾‘ï¼ˆæ ¹æ®ä½ çš„å®é™…CSVæƒ…å†µè°ƒæ•´ï¼‰
        df.columns = [c.upper() for c in df.columns]

    # æå–ç‰¹å¾å’Œæ ‡ç­¾
    try:
        features = df[feature_cols].values.astype(np.float32)
        labels = df["Label"].values # ç¡®ä¿æ ‡ç­¾åˆ—åä¸º Label
    except KeyError as e:
        raise KeyError(f"âŒ æ‰¾ä¸åˆ°åˆ—å: {e}. è¯·æ£€æŸ¥CSVæ–‡ä»¶çš„è¡¨å¤´æ˜¯å¦ä¸º ID, DATA0...DATA7, Label")

    return features, labels

def normalize_features(features):
    scaler = MinMaxScaler()
    features_norm = scaler.fit_transform(features)
    return features_norm, scaler

def window_to_rgb_image(window):
    """
    å°†27Ã—9çš„çª—å£æ˜ å°„åˆ°9Ã—9Ã—3çš„RGBå›¾åƒ
    é€»è¾‘ï¼š
    - window shape: (27, 9)
    - img shape: (9, 9, 3)
    """
    img = np.zeros((IMG_H, IMG_W, CHANNELS), dtype=np.float32)

    for t in range(WINDOW_SIZE):
        c = t // 9  # channel (0, 1, 2) --> å¯¹åº”æ—¶é—´æ®µ
        i = t % 9  # row (0-8)         --> å¯¹åº”æ¯ä¸ªé€šé“å†…çš„è¡Œ
        for f in range(FEATURE_DIM):   # col (0-8) --> å¯¹åº”ç‰¹å¾
            img[i, f, c] = window[t, f]

    return img

def majority_label(window_labels):
    """è·å–çª—å£å†…å‡ºç°æœ€å¤šçš„æ ‡ç­¾"""
    if len(window_labels) == 0:
        return "BENIGN" # fallback
    return Counter(window_labels).most_common(1)[0][0]

def split_into_attack_segments(labels):
    """
    ä¸ºäº†ä¿æŒæ”»å‡»çš„çº¯åº¦ï¼Œæˆ‘ä»¬åœ¨æ ‡ç­¾å˜åŒ–çš„åœ°æ–¹åˆ‡æ–­
    """
    segments = []
    start = 0

    for i in range(1, len(labels)):
        if labels[i] != labels[i - 1]:
            segments.append((start, i))
            start = i

    segments.append((start, len(labels)))
    return segments

def generate_windows_in_segment(features, labels, start, end):
    windows = []
    idx = start

    # åªæœ‰å½“æ®µè½é•¿åº¦å¤§äºçª—å£å¤§å°æ—¶æ‰å¤„ç†
    while idx + WINDOW_SIZE <= end:
        window_feat = features[idx:idx + WINDOW_SIZE]
        window_labels = labels[idx:idx + WINDOW_SIZE]

        label_name = majority_label(window_labels)

        windows.append({
            "features": window_feat,
            "label_name": label_name,
            "label_id": LABEL_MAP.get(label_name, -1) # å¦‚æœæœ‰æœªçŸ¥æ ‡ç­¾ï¼Œè®¾ä¸º-1
        })

        idx += STRIDE  # ä¸é‡å 

    return windows

def save_image(img, path):
    # å°† 0-1 float è½¬ä¸º 0-255 uint8
    img_uint8 = (img * 255).clip(0, 255).astype(np.uint8)
    Image.fromarray(img_uint8).save(path)

def process_dataset(csv_path):
    # 1. åŠ è½½æ•°æ®
    features, labels = load_data_no_timestamp(csv_path)

    print(f"âœ“ Data loaded. Shape: {features.shape}")

    # 2. å½’ä¸€åŒ–
    print("ğŸ”„ Normalizing features...")
    features, scaler = normalize_features(features)

    # 3. åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(OUTPUT_ROOT, exist_ok=True)

    # ä¸ºç›®æ ‡ç±»åˆ«åˆ›å»ºæ–‡ä»¶å¤¹
    for target in TARGET_CLASSES:
        if target in LABEL_MAP:
            os.makedirs(os.path.join(OUTPUT_ROOT, target), exist_ok=True)

    # ä¿å­˜scalerä»¥ä¾¿åç»­åå‘è½¬æ¢
    with open(os.path.join(OUTPUT_ROOT, "scaler.pkl"), 'wb') as f:
        pickle.dump(scaler, f)

    # 4. æŒ‰æ ‡ç­¾è¿ç»­æ€§åˆ†æ®µ (Data Segmentation)
    segments = split_into_attack_segments(labels)

    class_counter = Counter()
    total_saved = 0
    img_global_id = 0

    print(f"ğŸš€ Processing segments and generating images for: {TARGET_CLASSES}...")

    for start, end in tqdm(segments):
        # ä¼˜åŒ–ï¼šå¦‚æœè¿™ä¸€æ®µçš„æ ‡ç­¾æ ¹æœ¬ä¸æ˜¯æˆ‘ä»¬è¦çš„ï¼Œç›´æ¥è·³è¿‡ (å‡è®¾æ•´æ®µæ ‡ç­¾ä¸€è‡´)
        # å–æ®µè½ä¸­é—´çš„ä¸€ä¸ªæ ‡ç­¾åšæ£€æŸ¥
        segment_label = labels[start]
        if segment_label not in TARGET_CLASSES:
            continue

        # ç”Ÿæˆçª—å£
        windows = generate_windows_in_segment(features, labels, start, end)

        for w in windows:
            label_name = w["label_name"]

            # äºŒæ¬¡ç¡®è®¤ï¼šåªå¤„ç†ç›®æ ‡ç±»åˆ«
            if label_name in TARGET_CLASSES:
                img = window_to_rgb_image(w["features"])

                # æ–‡ä»¶åæ ¼å¼: Label_ID.png
                save_path = os.path.join(
                    OUTPUT_ROOT,
                    label_name,
                    f"{label_name}_{img_global_id}.png"
                )

                save_image(img, save_path)

                class_counter[label_name] += 1
                total_saved += 1
                img_global_id += 1

    return class_counter

if __name__ == "__main__":
    # è¯·ä¿®æ”¹è¿™é‡Œçš„è·¯å¾„æŒ‡å‘ä½ çš„ .csv æ–‡ä»¶
    csv_file_path = "CICIoV2024.csv"

    if not os.path.exists(csv_file_path):
        print(f"âŒ Error: File {csv_file_path} not found.")
    else:
        print("=" * 60)
        print("CICIoV2024 No-Timestamp Image Converter")
        print("=" * 60)

        counter = process_dataset(csv_file_path)

        print("\nğŸ“Š Generation Report:")
        for cls_name in TARGET_CLASSES:
            print(f"  - {cls_name}: {counter[cls_name]} images")


        print(f"Output directory: {OUTPUT_ROOT}")